{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e16f8d-0814-460e-a514-7d0ba46732ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04_stacking_and_meta.ipynb\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Optional external libraries ---\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    HAS_LGBM = True\n",
    "except ImportError:\n",
    "    HAS_LGBM = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    HAS_CAT = True\n",
    "except ImportError:\n",
    "    HAS_CAT = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c20a7737-f063-48e1-81f4-d590b54abd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654037bd-2b93-48fa-8bac-6b70c95c46c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (12445, 6)\n",
      "Features used: ['period', 'duration', 'depth', 'stellar_radius', 'stellar_mass', 'stellar_mag']\n"
     ]
    }
   ],
   "source": [
    "# --- Data loading ---\n",
    "DATA_DIR = \"../preprocessed_tabular_data\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_DIR, \"train_prepared.csv\"))\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, \"test_prepared.csv\"))\n",
    "\n",
    "# Separate features/labels\n",
    "X = train.drop(columns=[\"label\", \"tic_id\", \"obj_id\", \"object_name\", \"star_name\"], errors=\"ignore\")\n",
    "y = train[\"label\"]\n",
    "\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "print(\"Training shape:\", X.shape)\n",
    "print(\"Features used:\", X.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f2f37de-0fef-4499-9fd3-17c89c3fbd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define base learners for stacking ---\n",
    "\n",
    "base_learners = []\n",
    "\n",
    "# Example 1: LightGBM + GradientBoosting (paperâ€™s best combo)\n",
    "estimators_1 = [\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "if HAS_LGBM:\n",
    "    estimators_1.insert(0, (\"lgbm\", LGBMClassifier(n_estimators=300, learning_rate=0.1, random_state=42)))\n",
    "base_learners.append((\"Stack_LGBM_GB\", estimators_1))\n",
    "\n",
    "\n",
    "# Example 2: RF + XGB + LGBM + AdaBoost\n",
    "estimators_2 = [\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=300, random_state=42)),\n",
    "    (\"ada\", AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "if HAS_XGB:\n",
    "    estimators_2.append((\"xgb\", XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.1, max_depth=5,\n",
    "        random_state=42, use_label_encoder=False, eval_metric=\"logloss\"\n",
    "    )))\n",
    "if HAS_LGBM:\n",
    "    estimators_2.append((\"lgbm\", LGBMClassifier(n_estimators=300, learning_rate=0.1, random_state=42)))\n",
    "base_learners.append((\"Stack_RF_XGB_LGBM_Ada\", estimators_2))\n",
    "\n",
    "\n",
    "# Example 3: Diverse learners (always safe, all sklearn built-ins)\n",
    "estimators_3 = [\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=300, random_state=42)),\n",
    "    (\"et\", ExtraTreesClassifier(n_estimators=300, random_state=42)),\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, random_state=42))\n",
    "]\n",
    "base_learners.append((\"Stack_Diverse\", estimators_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4adb174-f1a8-4f00-8560-96f4b4c5c612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stack_LGBM_GB...\n",
      "Training Stack_RF_XGB_LGBM_Ada...\n",
      "Training Stack_Diverse...\n",
      "   accuracy  precision    recall        f1   roc_auc                  model\n",
      "0  0.803777   0.809975  0.896530  0.851035  0.870206          Stack_LGBM_GB\n",
      "1  0.815428   0.827149  0.891003  0.857868  0.882111  Stack_RF_XGB_LGBM_Ada\n",
      "2  0.816633   0.827424  0.893059  0.858958  0.883891          Stack_Diverse\n"
     ]
    }
   ],
   "source": [
    "# --- Meta-learner ---\n",
    "meta_learner = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# --- Cross-validation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "results = []\n",
    "\n",
    "for stack_name, est_list in base_learners:\n",
    "    print(f\"Training {stack_name}...\")\n",
    "    stack_model = StackingClassifier(\n",
    "        estimators=est_list,\n",
    "        final_estimator=meta_learner,\n",
    "        passthrough=False,   # only meta-learner sees predictions\n",
    "        cv=5,                # inner CV for stacking\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv_results = cross_validate(stack_model, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
    "    result_summary = {metric: np.mean(cv_results[f'test_{metric}']) for metric in scoring}\n",
    "    result_summary['model'] = stack_name\n",
    "    results.append(result_summary)\n",
    "\n",
    "# Collect results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Save results\n",
    "os.makedirs(\"../metrics\", exist_ok=True)\n",
    "results_df.to_csv(\"../metrics/stacking_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e6b615-a876-4a64-827b-47c90ce2a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a850eab7-2956-43aa-b16b-9801b010e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Tuning meta-learner for Stack_LGBM_GB...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 37\u001b[0m\n\u001b[0;32m     31\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     32\u001b[0m     y_prob \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     34\u001b[0m     stack_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: stack_name,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m\"\u001b[39m: grid\u001b[38;5;241m.\u001b[39mbest_params_,\n\u001b[1;32m---> 37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43maccuracy_score\u001b[49m(y_test, y_pred),\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision_score(y_test, y_pred),\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall_score(y_test, y_pred),\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1_score(y_test, y_pred),\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m: roc_auc_score(y_test, y_prob)\n\u001b[0;32m     42\u001b[0m     })\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# --- Compare with tuned single models ---\u001b[39;00m\n\u001b[0;32m     45\u001b[0m comparison_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stack_results \u001b[38;5;241m+\u001b[39m tuned_results)  \u001b[38;5;66;03m# tuned_results = from prev notebook\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Meta-learner hyperparameter tuning ---\n",
    "param_grid = {\n",
    "    \"final_estimator__C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"final_estimator__penalty\": [\"l2\"],\n",
    "    \"final_estimator__solver\": [\"lbfgs\", \"saga\"]\n",
    "}\n",
    "\n",
    "stack_results = []\n",
    "\n",
    "for stack_name, estimators in base_learners:\n",
    "    print(f\"\\nðŸ”Ž Tuning meta-learner for {stack_name}...\")\n",
    "    stack = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(max_iter=5000, random_state=42),\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        stack, param_grid, scoring=\"f1\", cv=5, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    stack_results.append({\n",
    "        \"model\": stack_name,\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_prob)\n",
    "    })\n",
    "\n",
    "# --- Compare with tuned single models ---\n",
    "comparison_df = pd.DataFrame(stack_results + tuned_results)  # tuned_results = from prev notebook\n",
    "display(comparison_df)\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(10,6))\n",
    "for metric in [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]:\n",
    "    plt.bar(comparison_df[\"model\"], comparison_df[metric], alpha=0.6, label=metric)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Performance Comparison: Tuned Models vs Stacks\")\n",
    "plt.legend()\n",
    "plt.save(\"../plots_of_experiment_on_tabular_dataset/Tuned_model_vs_Stacks\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd853a-28b9-4ac5-8250-146175a1e1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
